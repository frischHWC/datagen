#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#  http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
# TODO: Comment all settings here
# WARNING: required property to start the server
server.tomcat.additional-tld-skip-patterns=*.jar

# Vaadin
logging.level.org.atmosphere=warn
spring.mustache.check-template-location=false
vaadin.allowed-packages=com.vaadin,org.vaadin,dev.hilla,com.datagen
vaadin.exclude-urls=/swagger-ui/**,/api/v1/**
spring.jpa.defer-datasource-initialization=true
vaadin.productionMode=true


# Swagger
springdoc.swagger-ui.tryItOutEnabled=true

# General conf that should be set when starting the program
server.port=4242
app.name=Data Generator
hadoop.user=datagen
hadoop.home=/user/datagen

# General default Conf
generation.threads.default=4
generation.batches.default=20
generation.rows.default=20

datagen.home.directory=/tmp/datagen
datagen.model.path=src/main/resources/test-models/
datagen.model.received.path=#{datagen.home.directory}/models-received
datagen.model.generated.path=#{datagen.home.directory}/models-generated
datagen.model.store.path=#{datagen.home.directory}/models-store
datagen.commands.path=#{datagen.home.directory}/commands
datagen.credentials.path=#{datagen.home.directory}/credentials
datagen.analysis.path=#{datagen.home.directory}/analysis
datagen.scheduler.file.path=#{datagen.home.directory}/scheduler/commands.txt
datagen.users.file.path=#{datagen.home.directory}/users/user.txt
datagen.load.default.models=true

# TLS settings
ssl.server.enabled=false
# Un-comment and fill-in below properties to enable TLS (and set above property to true)
#server.ssl.key-store=dev-support/test_files/keystore.jks
#server.ssl.key-store-password=Test1234
#server.ssl.key-store-type=JKS
#server.ssl.key-alias=test-keystore
#server.ssl.key-password=Test1234
#server.ssl.trust-store=dev-support/test_files/truststore.jks
#server.ssl.trust-store-password=Test1234

# Auth config
security.basic.enabled=false
# Can be ldap, ldap-embedded, internal
datagen.auth.type=internal
# Internal Settings
datagen.admin.user=admin
datagen.admin.password=admin
# List of groups/users that will be admin
datagen.auth.internal.group.admins=admin
datagen.auth.internal.user.admins=superman
# LDAP Settings
datagen.auth.ldap.url=ldap://hostname.com:389/
datagen.auth.ldap.basedn=dc=frisch,dc=com
datagen.auth.ldap.bind.user=uid=admin,cn=users,cn=accounts,dc=frisch,dc=com
datagen.auth.ldap.bind.password=password
datagen.auth.ldap.group.base=cn=groups,cn=accounts
datagen.auth.ldap.group.filter=(member={0})
datagen.auth.ldap.group.search.subtree=true
datagen.auth.ldap.group.search.maxdepth=5
datagen.auth.ldap.group.role.attribute=cn
datagen.auth.ldap.group.convert.uppercase=true
datagen.auth.ldap.group.attribute=memberOf
datagen.auth.ldap.group.user.attribute=member
datagen.auth.ldap.group.reverse.search=true
datagen.auth.ldap.group.reverse.search.timeout=60
datagen.auth.ldap.user.base=cn=users,cn=accounts
datagen.auth.ldap.user.filter=(uid={0})
datagen.auth.ldap.user.attribute=uid
# List of groups/users that will be admin
datagen.auth.ldap.group.admins=admin_group
datagen.auth.ldap.user.admins=superman
# List of group/users that can access datagen (if empty, all can access)
datagen.auth.ldap.group.users=
datagen.auth.ldap.user.users=

# To setup embedded LDAP
#spring.ldap.embedded.ldif=classpath:users.ldif
#spring.ldap.embedded.base-dn=dc=springframework,dc=org
#spring.ldap.embedded.port=8389


# Kerberos config
kerberos.enabled=
kerberos.user=datagen
kerberos.keytab=datagen.keytab

# TLS Config
tls.enabled=
truststore.location=
truststore.password=
keystore.location=
keystore.password=

# These are default config file's path in a CDP cluster
# In case below settings are not set, these files are used to extrapolate them
hadoop.core.site.path=
hadoop.hdfs.site.path=
hadoop.ozone.site.path=
hadoop.hbase.site.path=
hadoop.hive.site.path=
solr.env.path=
kafka.conf.client.path=
schema.registry.conf.path=
kudu.conf.path=

# Auto-discovery Using CM - This replaces config files if it is set
cm.autodiscovery=false
cm.url=
cm.user=
cm.password=
cm.cluster.name=

# Other configurations are either derived from previous or set using APIs
# HDFS
hdfs.uri=
hdfs.auth.kerberos=#{kerberos.enabled}
# It is not needed to fill below configuration if KERBEROS is not activated
hdfs.auth.kerberos.user=#{kerberos.user}
hdfs.auth.kerberos.keytab=#{kerberos.keytab}


# HBASE
hbase.zookeeper.quorum=
hbase.zookeeper.port=
hbase.zookeeper.znode=
hbase.auth.kerberos=#{kerberos.enabled}
# It is not needed to fill below configuration if KERBEROS is not activated
hbase.auth.kerberos.user=#{kerberos.user}
hbase.auth.kerberos.keytab=#{kerberos.keytab}


# OZONE
ozone.service.id=
ozone.auth.kerberos=#{kerberos.enabled}
# It is not needed to fill below configuration if KERBEROS is not activated
ozone.auth.kerberos.user=#{kerberos.user}
ozone.auth.kerberos.keytab=#{kerberos.keytab}


# HIVE
hive.zookeeper.quorum=
hive.zookeeper.znode=
hive.auth.kerberos=#{kerberos.enabled}
# It is not needed to fill below configuration if KERBEROS is not activated
hive.security.user=#{kerberos.user}
hive.security.keytab=#{kerberos.keytab}
hive.truststore.location=#{truststore.location}
hive.truststore.password=#{truststore.password}


# SOLR
solr.zookeeper.quorum=
solr.zookeeper.znode=
solr.tls.enabled=#{tls.enabled}
solr.auth.kerberos=#{kerberos.enabled}
# It is not needed to fill below configuration if KERBEROS is not activated
solr.auth.kerberos.keytab=#{kerberos.keytab}
solr.auth.kerberos.user=#{kerberos.user}
solr.truststore.location=#{truststore.location}
solr.truststore.password=#{truststore.password}
solr.keystore.location=#{keystore.location}
solr.keystore.password=#{keystore.password}


# KAFKA
kafka.brokers=
kafka.security.protocol=
schema.registry.url=
schema.registry.tls.enabled=#{tls.enabled}
# It is not needed to fill below configuration if KERBEROS is not activated (i.e. protocol is PLAINTEXT)
kafka.keystore.location=#{keystore.location}
kafka.truststore.location=#{truststore.location}
kafka.keystore.password=#{keystore.password}
kafka.keystore.key.password=#{keystore.password}
kafka.truststore.password=#{truststore.password}
kafka.sasl.mechanism=
kafka.sasl.kerberos.service.name=
kafka.auth.kerberos.keytab=#{kerberos.keytab}
kafka.auth.kerberos.user=#{kerberos.user}


# KUDU
kudu.url=
kudu.auth.kerberos=#{kerberos.enabled}
# It is not needed to fill below configuration if KERBEROS is not activated
kudu.security.user=#{kerberos.user}
kudu.security.keytab=#{kerberos.keytab}
kudu.truststore.location=#{truststore.location}
kudu.truststore.password=#{truststore.password}

# S3
s3.access_key.id=
s3.access_key.secret=
s3.region=

# Azure
adls.account.name=
# Type can be either dfs or blob
adls.account.type=dfs
adls.sas.token=

# GCS
gcs.project.id=
# Only if using a service account key, otherwise use any other ADC login
gcs.account.key.path=
gcs.region=

# OLLAMA
spring.ai.ollama.base-url=localhost:57698
spring.ai.ollama.chat.enabled=true
spring.ai.ollama.chat.options.format=json
ollama.model.default=llama3
ollama.temperature.default=1.0
ollama.frequency_penalty.default=2.0
ollama.presence_penalty.default=2.0
ollama.top_p.default=2.0

# BEDROCK
bedrock.region=us-east-1
bedrock.model.default=amazon.titan-text-lite-v1
bedrock.temperature.default=1.0
bedrock.max_tokens.default=256
bedrock.access_key.id=
bedrock.access_key.secret=

# OPEN AI
# Let the api key here to 'test' (avoid auto-configuration of client not working)
spring.ai.openai.api-key=test
openai.api.key=
openai.temperature.default=2.0
openai.model.default=gpt-4o
openai.frequency_penalty.default=2.0
openai.presence_penalty.default=2.0
openai.max_tokens.default=256
openai.top_p.default=2.0

# Local LLM
local.llm.temperature.default=2.0
local.llm.frequency_penalty.default=2.0
local.llm.presence_penalty.default=2.0
local.llm.max_tokens.default=256
local.llm.top_p.default=2.0
